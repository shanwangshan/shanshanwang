<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-02-13 Tue 15:39 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Shanshan Wang (王珊珊)</title>
<meta name="author" content="Shanshan Wang" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="imagine_dark.css" />
<base target="_blank">
</head>
<body>
<div id="content" class="content">
<h1 class="title">Shanshan Wang (王珊珊)</h1>
<p align="center">&emsp;&emsp;<a href="https://scholar.google.com/citations?user=K8aK11cAAAAJ&hl=en"><img src="google_scholar.png" width=30" height="50"></a>&nbsp;&nbsp; &nbsp; &nbsp; <a href="https://github.com/shanwangshan"><img src="github.png" width=30" height="50"></a>&nbsp;&nbsp; &nbsp; &nbsp; <a href="https://www.linkedin.com/in/wangshanshan/"><img src="linkedin.png" width=30" height="50"></a></p

<p alt="image" style="float:left;margin:-40px 10px 10px 10px;" width="180px">
<a href="my_big.JPG" alt="image" style="float:left;margin:-40px 10px 10px 10px;" width="180px"><img src="my.JPG" alt="image" style="float:left;margin:-40px 10px 10px 10px;" width="180px" /></a>
<br />
<br />
<br />
<br />
</p>
<div id="outline-container-org7c4782f" class="outline-2">
<h2 id="org7c4782f">Hey (您好!)</h2>
<div class="outline-text-2" id="text-org7c4782f">
<p>
I am a PhD student in <a href="https://research.tuni.fi/machinelistening/">Machine Listening</a> and <a href="https://webpages.tuni.fi/arg/">Audio Research Group</a>(ARG)
from <a href="https://www.tuni.fi/en">Tampere University</a>. I am working in collaboration with assistant
professor <a href="http://www.cs.tut.fi/~mesaros/index">Annamaria Mesaros</a> and professor <a href="https://homepages.tuni.fi/tuomas.virtanen/">Tuomas Virtanen</a>. My research
interests include audio-visual feature learning, self-supervised
learning, audio signal processing, and general deep Learning. My
complete academic information can be found in <a href="https://drive.google.com/file/d/10ngKZmPPqbgQLynZbFd0n3aSuhEHTaWB/view">curriculum vitae.</a><br />
</p>
</div>
</div>

<div id="outline-container-orgffcfa7a" class="outline-2">
<h2 id="orgffcfa7a">Updates</h2>
<div class="outline-text-2" id="text-orgffcfa7a">
<ul class="org-ul">
<li><i>12.04 - 19.04, 2024</i>, will present our recent work in Seoul,
South Korea, <a href="https://2024.ieeeicassp.org/">ICASSP2024</a></li>
</ul>


<ul class="org-ul">
<li><i>12, 2023</i>, received Huawei award for best PhD publications</li>
</ul>


<ul class="org-ul">
<li><i>14.04 - 31.07, 2023</i>, worked as an intern in Huawei, Finland</li>
</ul>


<ul class="org-ul">
<li><i>04.06 - 10.06, 2023</i>, presented our recent work in Rhodes Island,
Greece, <a href="https://2023.ieeeicassp.org/">ICASSP2023</a></li>
</ul>


<ul class="org-ul">
<li><i>23.10, 2022</i>, presented our recent journal work in ECCV2022
workshop <a href="https://av4d.org/">AV4D: Visual Learning of Sounds in Spaces</a>, <a href="https://www.youtube.com/watch?v=pdRIznwovfs&amp;ab_channel=ChanganChen">Youtube link</a></li>
</ul>


<ul class="org-ul">
<li>Served as a reviewer for <a href="https://dcase.community/challenge2022/index">DCASE2022</a> and ECCV2022 workshop <a href="https://geometry.stanford.edu/voli/">VOLI</a></li>
</ul>


<ul class="org-ul">
<li><i>23.08 - 27.08, 2021</i>, selected as one of the ten finalists of the
<a href="https://eusipco2021.org/3-minute-thesis/">3 Minute Thesis (3MT)</a> contest, check my PhD thesis contest video
<a href="https://www.youtube.com/watch?v=GDbbfBA62t4&amp;t=13s&amp;ab_channel=ShanshanWang">Youtube link</a></li>
</ul>


<ul class="org-ul">
<li><i>01.03 - 01.07,2021</i>, one of the coordinators in DCASE2021 task1
subtaskb, <a href="http://dcase.community/challenge2021/task-acoustic-scene-classification">DCASE2021</a></li>
</ul>


<ul class="org-ul">
<li><i>02.2020 - present</i>, PhD student at Tampere University</li>
</ul>
</div>
</div>

<div id="outline-container-org4363fa1" class="outline-2">
<h2 id="org4363fa1">Publications</h2>
<div class="outline-text-2" id="text-org4363fa1">
<ul class="org-ul">
<li><i>S. Wang, S. Tripathy, T. Heittola, and A. Mesaros, "Positive and</i>
 <i>negative sampling strategies for self-supervised learning on</i>
 <i>audio-video data", in 2024 IEEE International Conference on Acoustics, Speech, and Signal
Processing workshop(ICASSP 2024):</i> <a href="https://github.com/shanwangshan/positive-negative-sampling-strategy">Code</a>,
<a href="https://arxiv.org/abs/2402.02899">Paper</a>.</li>
</ul>
<ul class="org-ul">
<li><i>S. Wang, S. Tripathy, and A. Mesaros, "Self-supervised learning of</i>
<i>audio representations using angular contrastive loss",</i>
<i>in 2023 IEEE International Conference on Acoustics, Speech, and Signal
Processing (ICASSP 2023):</i> <a href="https://github.com/shanwangshan/Self_supervised_ACL">Code</a>,
<a href="https://arxiv.org/abs/2211.05442">Paper</a>, and <a href="https://www.youtube.com/watch?v=78gdVod2gro&amp;ab_channel=ShanshanWang">Youtube link</a>.</li>
</ul>


<ul class="org-ul">
<li><i>S. Wang, A. Politis, A. Mesaros and T. Virtanen, "Self-supervised</i>
<i>learning of audio representations from audio-visual data using
spatial alignment", in ECCV2022 workshop:</i> <a href="https://av4d.org/">Workshop link</a>, <a href="https://www.youtube.com/watch?v=pdRIznwovfs&amp;ab_channel=ChanganChen">Youtube link</a>.</li>
</ul>


<ul class="org-ul">
<li><i>S. Wang, A. Politis, A. Mesaros and T. Virtanen, "Self-supervised</i>
<i>learning of audio representations from audio-visual data using</i>
<i>spatial alignment", in IEEE Journal of Selected Topics in Signal
Processing (JSTSP), 2022:</i> <a href="https://arxiv.org/abs/2206.00970">Paper</a>.</li>
</ul>


<ul class="org-ul">
<li><i>S. Wang, A. Mesaros, T. Heittola and T. Virtanen, "Audio-visual</i>
<i>scene classification: analysis of DCASE 2021 Challenge
submissions", 2021:</i> <a href="https://arxiv.org/abs/2105.13675">Paper</a>, <a href="https://www.youtube.com/watch?v=NAJErjrghhE">Youtube link</a>.</li>
</ul>


<ul class="org-ul">
<li><i>S. Wang, G. Naithani, A Politis, and T. Virtanen, "Deep neural</i>
<i>network Based Low-latency Speech Separation with Asymmetric
analysis-Synthesis Window Pair", in EUSIPCO, 2021:</i> <a href="https://arxiv.org/abs/2106.11794">Paper</a>, <a href="https://github.com/shanwangshan/asymmetric_window">Code</a>, <a href="https://youtu.be/ey_oPEN7L20">Youtube link</a>.</li>
</ul>


<ul class="org-ul">
<li><i>S. Wang, A. Mesaros, T. Heittola and T. Virtanen, "A Curated Dataset of Urban Scenes for Audio-Visual Scene Analysis," in Proc. ICASSP, 2021:</i> <a href="https://arxiv.org/abs/2011.00030">Paper</a>, <a href="https://github.com/shanwangshan/TAU-urban-audio-visual-scenes">Code</a>, <a href="https://www.youtube.com/watch?v=89EwgWGXkCs&amp;t=61s&amp;ab_channel=ShanshanWang">Youtube link</a>.</li>
</ul>


<ul class="org-ul">
<li><i>S. Wang, G. Naithani, and T. Virtanen, “Low-latency deep
clustering for speech separation,” in Proc. ICASSP, 2019:</i> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683437">Paper</a>, <a href="https://github.com/shanwangshan/Low-latency_deep_clustering_for_speech_separation">Code</a>, <a href="https://www.youtube.com/watch?v=3tGHxScf6As&amp;t=1s&amp;ab_channel=ShanshanWang">Youtube link</a>.</li>
</ul>
</div>
</div>


<div id="outline-container-orga71c42b" class="outline-2">
<h2 id="orga71c42b">Master thesis</h2>
<div class="outline-text-2" id="text-orga71c42b">
<p>
Graduation: 12.2019, <a href="https://core.ac.uk/download/pdf/280342574.pdf">Thesis</a>
</p>
</div>
</div>

<div id="outline-container-org5878637" class="outline-2">
<h2 id="org5878637">Contacts</h2>
<div class="outline-text-2" id="text-org5878637">
<p>
Address: Tampere University, Hervanta Campus, Tietotalo, Room No: TF405<br />
Email: shanshan.wang@tuni.fi<br />
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Shanshan Wang</p>
<p class="date">Created: 2024-02-13 Tue 15:39</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
